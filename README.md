# Optimization

An optimization problem consists of maximizing or minimizing a real function by systematically choosing input values from within an allowed set and computing the value of the function. The generalization of optimization theory and techniques to other formulations constitutes a large area of applied mathematics. More generally, optimization includes finding "best available" values of some objective function given a defined domain (or input), including a variety of different types of objective functions and different types of domains.

# Meta-heuristic-optimization
Algorithms with stochastic components were often referred to as heuristic in the past, though the recent literature tends to refer to them as metaheuristics.
Two major components of any metaheuristic algorithms are: intensification and diversification, or exploitation and exploration
 Diversification means to generate diverse solutions so as to explore the search space on a global scale, while intensification means to focus the search in a local region knowing that a current good solution is found in this region. A good balance between intensification and diversification should be found during the selection of the best solutions to improve the rate of algorithm convergence. The selection of the best ensures that solutions will converge to the optimum, while diversification via randomization allows the search to espace from local optima and, at the same time, increases the diversity of solutions. A good combination of these two major components will usually ensure that global optimality is achievable.

## DE & GE

Differential Evolution uses mutation as a search mechanism and
selection to direct the search toward the prospective regions in the feasible region.
Genetic Algorithms generate a sequence of populations by using selection mechanisms.
Genetic Algorithms use crossover and mutation as search mechanisms. The principal
difference between Genetic Algorithms and Differential Evolution is that Genetic
Algorithms rely on crossover, a mechanism of probabilistic and useful exchange of
information among solutions to locate better solutions, while evolutionary strategies use
mutation as the primary search mechanism. 

# Differential Evolution
DE is a population based search technique which utilizes NP variables as population of D
dimensional parameter vectors for each generation. The initial population is chosen
randomly if no information is available about the problem. In the case of the available
preliminary solution, the initial population is often generated by adding normally
distributed random deviations to the preliminary solution. The basic idea behind DE is a
new scheme for generating trial parameter vectors. DE generates new parameter vectors
by adding the weighted difference vector between two population members to a third
member. If the resulting vector yields a lower objective function value than a
predetermined population member, the newly generated vector replaces the vector with
which it was compared.
## Loss Graph
![de loss](https://user-images.githubusercontent.com/23000971/33500182-fcb5bf52-d6fd-11e7-96dc-c8718d1ac515.JPG)

# Genetic Algorithms
In GAs, we have a pool or a population of possible solutions to the given problem. These solutions then undergo recombination and mutation (like in natural genetics), producing new children, and the process is repeated over various generations. Each individual (or candidate solution) is assigned a fitness value (based on its objective function value) and the fitter individuals are given a higher chance to mate and yield more “fitter” individuals. This is in line with the Darwinian Theory of “Survival of the Fittest”.
In this way we keep “evolving” better individuals or solutions over generations, till we reach a stopping criterion.

## Loss Graph
![geloss](https://user-images.githubusercontent.com/23000971/33500203-1c4f662e-d6fe-11e7-96bd-e0c26407b96f.JPG)


